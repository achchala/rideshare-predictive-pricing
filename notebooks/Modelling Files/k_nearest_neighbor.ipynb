{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use K-Nearest Neighbors (KNN) Regression because it is simple, easy to use, and doesn't require any assumptions about how the data is distributed. This is great for our complex dataset where traditional assumptions may not hold true. KNN also doesn't require a lot of tweaking, which allows us to focus on refining our feature set. \n",
    "\n",
    "We're particularly interested in understanding the impact of the features we engineered, and although KNN doesn't provide feature importance scores, we can evaluate the significance of our chosen features by analyzing how different feature configurations affect KNN's performance. This will help us understand which features are most important and how they relate to our target variable. This approach will allow us to refine our model and gain valuable insights into the underlying data relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>name</th>\n",
       "      <th>distance</th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temperatureHigh</th>\n",
       "      <th>apparentTemperatureHigh</th>\n",
       "      <th>uvIndex</th>\n",
       "      <th>precipIntensityMax</th>\n",
       "      <th>temperatureMax</th>\n",
       "      <th>apparentTemperatureMax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>42.52</td>\n",
       "      <td>40.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>42.52</td>\n",
       "      <td>40.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.66</td>\n",
       "      <td>33.83</td>\n",
       "      <td>32.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>33.83</td>\n",
       "      <td>32.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>33.83</td>\n",
       "      <td>32.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>33.83</td>\n",
       "      <td>32.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.86</td>\n",
       "      <td>43.83</td>\n",
       "      <td>38.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>43.83</td>\n",
       "      <td>38.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.64</td>\n",
       "      <td>33.83</td>\n",
       "      <td>32.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>33.83</td>\n",
       "      <td>32.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  name  distance  source  destination  precipIntensity  humidity  \\\n",
       "0   12.0     4      1.11       6           11           0.0000      0.60   \n",
       "1   16.0     0      1.11       6           11           0.0000      0.66   \n",
       "2    7.5     3      1.11       6           11           0.0000      0.56   \n",
       "3    7.5     5      1.11       6           11           0.0567      0.86   \n",
       "4   26.0     1      1.11       6           11           0.0000      0.64   \n",
       "\n",
       "   temperatureHigh  apparentTemperatureHigh  uvIndex  precipIntensityMax  \\\n",
       "0            42.52                    40.53        0              0.0003   \n",
       "1            33.83                    32.85        0              0.0001   \n",
       "2            33.83                    32.85        0              0.0001   \n",
       "3            43.83                    38.38        0              0.1252   \n",
       "4            33.83                    32.85        0              0.0001   \n",
       "\n",
       "   temperatureMax  apparentTemperatureMax  \n",
       "0           42.52                   40.53  \n",
       "1           33.83                   32.85  \n",
       "2           33.83                   32.85  \n",
       "3           43.83                   38.38  \n",
       "4           33.83                   32.85  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data_feature_engineering.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price', axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264454, 12) (66114, 12) (264454,) (66114,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining K Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose specific k values (3, 4, 5, 7, 9, 11) for testing in the K-Nearest Neighbors (KNN) Regression model based on a strategic approach aimed at balancing model complexity and generalization ability. Starting with a small number of neighbors allows the model to capture more detailed patterns in the data, but this may lead to overfitting where the model is too closely tailored to the training set. As the number of neighbors increases, the model takes a broader context into account, reducing variance but potentially underfitting by smoothing predictions too much.\n",
    "\n",
    "Our chosen k values provide a range of models from fine-grained to more generalized, allowing us to investigate the trade-off between capturing detailed data relationships and maintaining robustness to unseen data. This range avoids the extremes of too few (sensitive to noise) and too many neighbors (losing relevant information), aiming to find the optimal balance where the model performs best on unseen data, measured by metrics like R-squared, MSE, and RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 for 3 neighbors: 0.9167395562237907\n",
      "MSE for 3 neighbors: 6.026877396954081\n",
      "RMSE for 3 neighbors: 2.4549699380957968\n",
      "R^2 for 4 neighbors: 0.917296154510147\n",
      "MSE for 4 neighbors: 5.986587560879693\n",
      "RMSE for 4 neighbors: 2.4467504083742773\n",
      "R^2 for 5 neighbors: 0.9160188768906401\n",
      "MSE for 5 neighbors: 6.079044377892731\n",
      "RMSE for 5 neighbors: 2.4655718156023627\n",
      "R^2 for 7 neighbors: 0.9128714870104566\n",
      "MSE for 7 neighbors: 6.306870847077373\n",
      "RMSE for 7 neighbors: 2.511348412123928\n",
      "R^2 for 9 neighbors: 0.9091185582051136\n",
      "MSE for 9 neighbors: 6.578529761724698\n",
      "RMSE for 9 neighbors: 2.5648644723892717\n",
      "R^2 for 11 neighbors: 0.9058390007629915\n",
      "MSE for 11 neighbors: 6.815923291274751\n",
      "RMSE for 11 neighbors: 2.6107323285382495\n"
     ]
    }
   ],
   "source": [
    "neighbors_settings = [3, 4, 5, 7, 9, 11]\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # Build the model\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Train the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Test the model\n",
    "    # R-squared\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    # Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse) \n",
    "    \n",
    "    print(f\"R^2 for {n_neighbors} neighbors: {r2}\")\n",
    "    print(f\"MSE for {n_neighbors} neighbors: {mse}\")\n",
    "    print(f\"RMSE for {n_neighbors} neighbors: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation of the KNN regression model across varying numbers of neighbors reveals the superiority of the model with 4 neighbors in terms of key performance metrics. This model stands out with an impressive R^2 value of 0.9173, indicating a strong ability to explain the variance in the target variable. Additionally, it showcases the lowest Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) of 5.9866 and 2.4468, respectively, suggesting the smallest average prediction error.\n",
    "\n",
    "Taken together, these results suggest that the KNN model with 4 neighbors achieves the best balance between capturing the underlying patterns in the data and generalizing well to unseen data. This model's performance is particularly noteworthy, providing a compelling argument for its use in modeling and prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawbacks with Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the KNN regression model, especially with 4 neighbors, has shown impressive performance, it's not without limitations. Some of the possible limiations or drawbacks are: \n",
    "1. KNN can be computationally intensive, particularly as the dataset size grows. This is because it requires computing the distance between each query point and all other points in the dataset to identify the nearest neighbors. As a result, scalability can become an issue for large datasets.\n",
    "\n",
    "2. KNN's performance heavily relies on the choice of distance metric and feature relevance. Irrelevant or highly correlated features can significantly degrade the model's accuracy.\n",
    "\n",
    "3. KNN doesn't handle categorical variables well and requires pre-processing to convert them into a suitable numeric format.\n",
    "\n",
    "4. KNN makes predictions based solely on the nearest neighbors, it can be sensitive to noise in the data, leading to overfitting, especially with an excessively low value of k.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msci446",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
